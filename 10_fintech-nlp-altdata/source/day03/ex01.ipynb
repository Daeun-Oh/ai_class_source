{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e244f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\Daeun-ai\\10 Fintech-NLP-AltData\\source\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\admin\\Desktop\\Daeun-ai\\10 Fintech-NLP-AltData\\source\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--LGAI-EXAONE--EXAONE-3.5-2.4B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2451f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- configuration_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct:\n",
      "- modeling_exaone.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Fetching 2 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [13:29<00:00, 404.60s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.59it/s]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\",\n",
    "                model=\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\", # ìƒì„±í˜• ëª¨ë¸ (ë””ì½”ë” ê¸°ë°˜ ëª¨ë¸)\n",
    "                tokenizer=tokenizer,\n",
    "                trust_remote_code=True)  # ì‹¤í–‰ í• ë˜ë§ë˜ ì•ˆ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edb8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"ë„ˆëŠ” ì‡¼í•‘ëª° í™ˆí˜ì´ì§€ì— ì˜¬ë¼ì˜¨ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” Q&A ì±—ë´‡ì´ì•¼. \\\n",
    "                 í™•ì •ì ì¸ ë‹µë³€ì„ í•˜ì§€ ë§ê³  ì œí’ˆ ë‹´ë‹¹ìê°€ ì •í™•í•œ ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ \\\n",
    "                 ì‹œê°„ì´ í•„ìš”í•˜ë‹¤ëŠ” ê°„ë‹¨í•˜ê³  ì¹œì ˆí•œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.\"},\n",
    "    {\"role\": \"user\", \"content\": \"ì´ ë‹¤ì´ì–´ë¦¬ì— ë‚´ë…„ë„ ê³µíœ´ì¼ì´ í‘œì‹œë˜ì–´ ìˆë‚˜ìš”?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd7a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' oliÃ©ë¬¼ë¡ í•˜ì‹œëŠ” ì •ë³´í™•ì¸ ì°¨ ë‹´ë‹¹ìë¶„ë“¤í•œí…Œë‚˜ê»˜ í™•ì¸ì ˆæ¬¡ìˆœìœ„ì—ì„œ ì§ˆë¬¸ ë¶€íƒë“œë ¤ìš”!\\\\ ê·¸ëŸ´ ë§Œí•œ ì²˜ë¦¬ ì†ë„ ë°›ì•„ë³´ë©´ì„œë„ ìµœì„ ì´ë‹ˆ ì¢€ ë„ì™€ë“œë ¤ì£¼ì‹œëŠ”ì§€ í•œë²ˆ ë¬¸ì˜ë“œë¦´ê¹Œìš”?> ì •í™• details íŒŒì•…ì— ì¦‰ì‹œ í•„ìš”í•œê°€ë²¼ë¦¬ì‹  ì¶”ê°€ ìš”ì²­ì´ë¼ë“ ê°€ë„ ê°™ì´ ì²´í¬ë°”ë¼ ì£¼ì„¸ìš”~~ ğŸ’«âœ¨  í™•ì¸ ì™„ë£Œ ì¦‰ì‹œ í”¼ë“œë°± ë³´ë‚´ ë“œlify ë“œë¦´ê²Œìš”ã€‚! ğŸ˜‰ Thank ï¿½ Pandoraí‘œ  âœ¨â¤âœ¨ \\t// ê°„ëµì²´ ë³€í˜•  ì œí’ˆ ì¶œì‹œ ë° ë‚´ë…„ ë‚ ì§œê°€ ê³ ì •í˜•ì‹ì´ì—¬ì„œ ìƒì„¸íˆ ê²€í† í•˜ê¸° ìœ„í•´ ì‹ ì†í•¨ì„ ë³´ì¥ë°›ê³  ë°”ë¡œë°”ë¡œ í”¼ë“œë°± í•„ìš”í•˜ë‹ˆ í™•ì¸ë°”ë˜ìš”!! í™•ì¸ ë¹ ë¥´ì‹œë ¤ê³  ë„ì™€ìš”! ğŸ’ ğŸ‘ºâ™Šâš¡â’ ğŸ˜‰ThankYOUâ˜ Forasking   ë‹¤ì‹œ ê°„ë‹¨íˆ ëŒë ¤ë´…ì‹œë‹¤:: ë‹´ë‹¹ì ì‹œê°„ í™•ì¸í•´ì„œ ê°€ì¥ ë¹¨ë¼ê²Œ ë‹µ ë“œlify ë¶€íƒë“œë¦½ë‹ˆë‹¤^^ ì •í™• ë‚´ìš© ì•Œì•„ë³´ë ¤ëŠ” ì‹ ì†í•´ë³´ì´ë©´ ì•„ì£¼ ë„ìš¸ ìˆ˜ë¡ ìµœê³  ğŸ‘‡ğŸ·âœ¨â­ğŸ… ğŸ’°âœ‚â—‡âœ¨ğŸ! ê·¸ëŸ¼ ì—°ë½ë“œë¦¬ë„ë¡ìš” ï¿½'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(messages, max_new_tokens=200, return_full_text=False, do_sample=True, temperature=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff593de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'ì•ˆë…•í•˜ì„¸ìš”! ë‹¤ì´ì–´ë¦¬ì˜ ì •í™•í•œ ê³µíœ´ì¼ í‘œì‹œ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ë“œë¦¬ê¸° ìœ„í•´ì„œëŠ” ì œí’ˆì— ëŒ€í•œ ì¢€ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ëŠ” ì œí’ˆ ë‹´ë‹¹ìê»˜ì„œ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì´ë‹ˆê¹Œìš”, ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”! ê³§ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(messages, max_new_tokens=200, return_full_text=False, do_sample=True, \n",
    "     top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
