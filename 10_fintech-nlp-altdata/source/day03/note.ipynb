{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c75bd6",
   "metadata": {},
   "source": [
    "# 대규모 언어 모델로 텍스트 생성하기\n",
    "\n",
    "**디코더 기반의 트랜스포머 모델**을 알아보자.\n",
    "\n",
    "## 키워드 정리\n",
    "- EXAONE\n",
    "    - LG AI 연구원에서 만든 트랜스포머 디코더 기반의 대규모 언어 모델 (디코더 기반: 인코더가 없다 -> 크로스 어텐션이 없다)\n",
    "    - 3.5버전은 한국어와 영어를 잘 이해하며 비교적 적은 모델 파라미터를 가진 모델 중에서 경쟁력이 있음\n",
    "    - 최신 LLM에서 채택하는 여러 기술을 사용하고 있음\n",
    "    - 그룹 쿼리 어텐션, 실루 활성화 함수, RMS 정규화, 로터리 위치 임베딩 등\n",
    "- 토큰 디코딩\n",
    "    - 대규모 언어 모델이 출력한 로짓을 바탕으로 다음 토큰을 선택하는 과정\n",
    "    - 가장 기본적인 방법은 로짓을 소프트맥스 함수에 통과시켜 확률로 바꾼 후 이 확률을 기반으로 다음 토큰을 선택\n",
    "    - 온도 파라미터를 높이면 비교적 낮은 확률의 토큰이 선택될 가능성을 높일 수 있음\n",
    "    - 최상위 로짓의 일부 토큰을 선택하는 top-k 방식과 누적 확률의 임곗값으로 토큰을 선택하는 **top-p** 방식이 널리 사용됨\n",
    "- GPT는 오픈 AI에서 개발된 트랜스포머 디코더 기반의 대규모 언어 모델\n",
    "    - GPT-2는 공개 되어 있지만 GPT-3 부터는 클로즈드 소스 정책을 유지하고 있\n",
    "    - GPT-3.5를 기반으로 하는 ChatGPT는 인공지능 분야에 큰 영향을 미쳤\n",
    "    - 최신 GPT-4o 모델은 다양한 작업에서 뛰어난 성능을 내는 모델 중 하나\n",
    "    - ChatGPT 웹 인터페이스 또는 파이썬 같은 프로그래밍 언어를 위해 제공되는 API를 통해 이런 모델을 사용할 수 있\n",
    "\n",
    "### transformers\n",
    "- AutoTokenizer\n",
    "    - 허깅페이스에서 제공하는 사전 훈련된 LLM 모델의 토크나이저를 직접 로드하기 위한 클래스\n",
    "    - `from_pretrained()` 클래스 메서드에 허깅페이스 모델 경로를 전달하여 불러올 수 있\n",
    "    - 비슷하게 트랜스포머 디코더 기반의 LLM 모델을 불러오려면 AutoModelForCausalLM 클래스를 사용합니다.\n",
    "파이프라인 객체를 호출할 때 다음과 같은 매개변수를 사용할 수 있습니다.\n",
    "max_new_tokens 매개변수는 모델이 생성할 최대 토큰 개수를 설정합니다.\n",
    "return_full_text 매개변수를 False로 지정하면 모델이 생성한 텍스트만 반환합니다. 기본값은 True 입니다.\n",
    "do_sample 매개변수를 True로 지정하면 토큰 확률을 기반으로 다음 토큰을 선택합니다. 기본값은 False 입니다.\n",
    "temperature 매개변수는 모델이 출력한 로짓의 분포를 조정하는 온도 파라미터입니다. 1.0보다 크면 토큰의 선택 가능성을 고르게 만들고 1.0보다 작으면 높은 확률의 토큰이 선택될 가능성이 더 커집니다. 기본값은 1.0입니다.\n",
    "top_k 매개변수는 가장 큰 확률을 가진 토큰 k개를 다음 토큰의 후보로 설정합니다. 기본값은 50이며 이런 디코딩 전략을 top-k 샘플링이라고 합니다.\n",
    "top_p 매개변수를 1.0보다 작게 설정하면 확률 크기 순으로 토큰을 나열했을 때 누적 확률이 지정한 값을 넘기지 않을 때까지 후보 토큰으로 설정합니다. 기본값은 1.0이며 이런 디코딩 전략을 top_p 샘플링이라고 합니다.\n",
    "openai\n",
    "OpenAI 클래스는 오픈 AI의 API호출을 위한 클라이언트 객체를 만듭니다./\n",
    "api_key 매개변수에는 오픈 AI에서 발급받은 API 키를 지정합니다. 이 매개변수를 지정하지 않으면 OPENAI_API_KEY 환경 변수에 저장되어 값을 이용합니다.\n",
    "OpenAI.chat.completion.create() 메서드는 채팅 완성 API를 호출하고 GPT 모델의 응답을 반환합니다.\n",
    "model 매개변수에 사용할 모델 아이디를 지정합니다.\n",
    "messages 매개변수에 모델에게 전달할 대화 메세지를 입력합니다. 멀티모달 모델일 경우 텍스트 외에 이미지나 오디오 등을 전달할 수 있습니다.\n",
    "temperature 매개변수로 0~2 사이의 온도 파라미터를 조정합니다. 기본값은 1입니다.\n",
    "top_p 매개변수로 top-p 샘플링을 설정합니다. 기본값은 1입니다.\n",
    "max_completion_tokens 매개변수로 모델이 생성할 최대 토큰 수를 지정합니다.\n",
    "\n",
    "\n",
    "## exaone\n",
    "[링크]https://huggingface.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
