{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1f3340",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f734d4aa",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘\n",
    "\n",
    "- 어텐션 매커니즘attention mechanism은 순환 신경망 기반 인코더-디코더 모델의 성능을 크게 향상시킨 기술입니다. 기존에는 디코더가 인코더의 마지막 은닉 상태만 참고하여 번역을 수행했지만, 어텐션 메커니즘을 사용하면 인코더의 모든 타임스텝에서 계산된 은닉 상태를 활용할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "디코더가 두 번째 타임스텝에서 \"love\"라는 토큰을 생성할 때, 인코더의 모든 타임스텝에서 출력된 은닉 상태를 참고합니다. 즉, 디코더는 단순히 인코더의 마지막 은닉 상태만 활용하는 것이 아니라 각각의 타임스텝에서 생성된 모든 은닉 상태를 참조하여 출력을 만듭니다.\n",
    "어텐션 가중치\n",
    "디코더가 인코더의 은닉 상태를 활용하는 방식은 가중치를 곱하는 형태로 이루어집니다. 디코더는 인코더의 모든 타임스텝에서 생성된 은닉 상태를 동일하게 참고하는 것이 아니라, 각 은닉 상태마다 가중치를 다르게 적용하여 더 중요한 정보를 강조합니다. 이러한 가중치는 다른 모델 파라미터와 마찬가지로 신경망을 훈련하면서 함께 학습됩니다.\n",
    "위 그림에서는 어텐션 가중치를 a1, a2, a3으로 나타냈습니다. 이 값들은 각각 다른 값을 가지며, 디코더의 타임스텝마다 달라질 수 있습니다. 이를 디코더가 타임스텝에서 인코더의 각기 다른 은닉 상태에 주의를 기울인다고 이해할 수 있습니다. 디코더가 입력 토큰마다 중요도를 다르게 부여하는 이런 방식을 어텐션 메커니즘이라고 합니다.\n",
    "어텐션 매커니즘의 장점과 단점\n",
    "어텐션 메커니즘은 긴 텍스트를 처리할 때 정보 손실을 줄이는 데 매우 효과적입니다. 인코더의 모든 타임스텝에서 생성된 은닉 상태를 참고하여 더 정확한 출력을 생성할 수 있기 때문입니다.\n",
    "하지만 이 방식에도 단점이 있습니다. 어텐션 가중치를 계산하기 위해 인코더의 모든 타임스텝에서 생성된 은닉 상태를 저장해야 하므로 연산량이 증가합니다. 따라서 인코더가 처리할 수 있는 타임스텝의 최대 개수를 정해야 하며, 이로 인해 입력 텍스트의 길이가 제한될 수 있습니다. 또한, 어텐션을 사용해도 여전히 한 번에 한 토큰씩 처리해야 하는 한계는 남아 있습니다. 이러한 문제에도 불구하고, 어텐션 매커니즘을 사용한 획기적인 모델이 등장하면서 기계 번역은 물론, 자연어 처리 전 분야에 혁명을 일으켰습니다.\n",
    "\n",
    "\n",
    "## 트랜스포머\n",
    "\n",
    "아래는 인코더 블록 1개\n",
    "Attention is All need\n",
    "```text\n",
    "                                ⭐ Multi Head Attention ⭐\n",
    "                              ╒════════════════════════════╗\n",
    "                              │ ┌─────┐                    ║\n",
    "                          ┌───┼─┤  H  │ --> Query V ──┐    ║\n",
    "                          │   │ └─────┘               │    ║\n",
    "                          │   │                       ├─┐  ║\n",
    "            ┌───────────┐ │   │ ┌─────┐               │ │  ║  \n",
    "Input Text ─┤ Imbedding ├─┼───┼─┤  H  │ --> Key V   ──┘ │  ║  ┌────────┐  ┌─────────┐    ╭─────╮    ┌──────────┐\n",
    "            └───────────┘ │   │ └─────┘                 ├──╬══╡ H      ├──┤ Dropout ├────┤  +  ├────┤ Layer J  ├──┄┄┄┄\n",
    "                          │   │                         │  ║  └────────┘  └─────────┘    ╰─────╯    └──────────┘\n",
    "                          │   │ ┌─────┐                 │  ║\n",
    "                          └───┼─┤  H  │ --> Value V ────┘  ║\n",
    "                              │ └─────┘                    ║\n",
    "                              └────────────────────────────╜\n",
    "\n",
    "\n",
    "\n",
    "      ┌────────┐\n",
    "┄┄┄┄──┤ H      ├\n",
    "      └────────┘\n",
    "```\n",
    "\n",
    "⭐: **어텐션** 점수를 만들고 출력을 만듦 (어떤 토큰을 강조할 것인가?에 대한 가중치)\n",
    "\n",
    "밀집층을 쌓을수록 성능 떨어짐(오래된 학습을 잊어버림) -> 잔차 연결 추가\n",
    "잔차 연결: 출력에 입력을 더해줌 -> 스케일이 커지기 때문에 층 정규화(=토큰 별로 정규화) 필요(학습 안정화)\n",
    "피드 포워드 네트워크:\n",
    "첫번째 밀집층 - 렐루(활성화함수) 존재\n",
    "두번째 밀집층 - 활성화 함수 X\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
