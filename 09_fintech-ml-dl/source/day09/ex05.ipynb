{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08470720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Using cached torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480431a",
   "metadata": {},
   "source": [
    "책에는 없는 듯하다...\n",
    "\n",
    "#### PyTorch를 이용해보자!\n",
    "- PyTorch = Tensor + Autograd + Neural Network\n",
    "\n",
    "| 기능 영역       | 예시                                                            |\n",
    "| -------------- | -------------------------------------------------------------- |\n",
    "| **Tensor 연산** | `torch.tensor()`, `torch.matmul()`, `torch.sum()` 등           |\n",
    "| **자동 미분**    | `tensor.requires_grad = True`, `loss.backward()`              |\n",
    "| **신경망 구성**  | `torch.nn.Linear`, `torch.nn.Sequential`, `torch.nn.Module` 등 |\n",
    "| **옵티마이저**   | `torch.optim.SGD`, `Adam`, `RMSprop`                           |\n",
    "| **GPU 연산**    | `tensor.to('cuda')` 또는 `.cuda()`                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f48520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:04<00:00, 6.35MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 112kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 2.03MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 3.62MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "fm_train = FashionMNIST(root='.', train=True, download=True)  # 훈련세트\n",
    "fm_test = FashionMNIST(root='.', train=False, download=True)  # 테스트세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02618e27",
   "metadata": {},
   "source": [
    "FashionMNIST를 해당 파일 경로에 저장했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2f9d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fm_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb108e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "torch.Size([60000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 훈련세트, 테스트세트 개수\n",
    "print(fm_train.data.shape, fm_test.data.shape)\n",
    "print(fm_train.targets.shape, fm_test.targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc54ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = fm_train.data\n",
    "train_target = fm_train.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad73f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 (0~1)\n",
    "train_scaled = train_input / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c552e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련세트, 검증세트 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82470e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 10]                  --\n",
       "├─Flatten: 1-1                           [32, 784]                 --\n",
       "├─Linear: 1-2                            [32, 100]                 78,500\n",
       "├─ReLU: 1-3                              [32, 100]                 --\n",
       "├─Linear: 1-4                            [32, 10]                  1,010\n",
       "==========================================================================================\n",
       "Total params: 79,510\n",
       "Trainable params: 79,510\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.54\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.32\n",
       "Estimated Total Size (MB): 0.45\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 층 구성 (Flatten 포함)\n",
    "import torch.nn as nn  # nn: neural network (신경망 모듈)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),        # 2D 이미지(28*28)를 1D 벡터(784차원)로 펼침\n",
    "    nn.Linear(784, 100), # 입력층: 노드 28*28=784개 → 은닉층: 유닛 100개\n",
    "    nn.ReLU(),           # 활성화 함수: ReLU\n",
    "    nn.Linear(100, 10)   # 은닉층: 유닛 100개 → 출력층: 클래스 10개\n",
    ")\n",
    "\n",
    "# 층 구성 요약 정보 - input_size=(배치_사이즈, ...) (다만, 이전과 달리 배치 사이즈 기본값은 없다)\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(32, 28, 28))  # 배치 사이즈를 32로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e121a4",
   "metadata": {},
   "source": [
    "- 맥의 경우 - mps / 그래픽 가속기\n",
    "```python\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e8a977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 또는 CPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # 모델에 GPU 또는 CPU 연산 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250eba0",
   "metadata": {},
   "source": [
    "- 활성화 함수 설정\n",
    "    - 이진 분류: nn.BCELoss() ->  손실함수 + 출력함수(sigmoid)\n",
    "    - 다중 분류: nn.CrossEntropyLoss() -> 손실함수 + 출력함수(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4239980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수(loss), 옵티마이저(optimizer) 설정\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 손실함수 - Cattegorical Crossentropy\n",
    "optimizer = optim.Adam(model.parameters())  # 2번째 매개변수: learning_rate=? - 기본값 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6c2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1, loss: 0.5466\n",
      "epochs: 2, loss: 0.4030\n",
      "epochs: 3, loss: 0.3614\n",
      "epochs: 4, loss: 0.3340\n",
      "epochs: 5, loss: 0.3125\n"
     ]
    }
   ],
   "source": [
    "# 학습 (fit은 없다. 하나하나 코드를 짜야 함.)\n",
    "\n",
    "epochs = 5\n",
    "batches = int(len(train_scaled) / 32)  # 1500 (1 epoch당 1500번 학습)\n",
    "for epoch in range(epochs):\n",
    "    model.train()   # 학습 시작을 알려줌\n",
    "    train_loss = 0  # loss값의 합\n",
    "    for i in range(batches):  # 미니배치 경사 하강법\n",
    "        # 1번째 epoch: 0 ~ 31, 2번째 epoch: 32 ~ 63, ... 1500번째 epoch: ~ len(train_scaled) - 1\n",
    "        inputs = train_scaled[i * 32 : (i + 1) * 32].to(device)\n",
    "        targets = train_target[i * 32 : (i + 1) * 32].to(device)\n",
    "\n",
    "        optimizer.zero_grad()    # 그래디언트 초기화\n",
    "        outputs = model(inputs)  # 추론\n",
    "\n",
    "        loss = criterion(outputs, targets)  # loss(손실)값 구함\n",
    "        loss.backward()   # 역전파\n",
    "        optimizer.step()  # 모델 파라미터(가중치, 절편) 업데이트\n",
    "        train_loss += loss.item()  # 현재 배치의 loss를 더함\n",
    "    print(f\"epochs: {epoch + 1}, loss: {train_loss / batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdb67919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 8, 7, 4, 8, 4, 1, 0, 4, 5])\n",
      "accuracy:0.8771, loss:0.3431\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # 모델 평가\n",
    "with torch.no_grad():  # 평가 시에는 그래디언트 연산 X\n",
    "    val_scaled = val_scaled.to(device)\n",
    "    val_target = val_target.to(device)\n",
    "    outputs = model(val_scaled)\n",
    "    # print(outputs[:10])\n",
    "\n",
    "    # argmax로 학습 결과 배열 가져오기\n",
    "    predicts = torch.argmax(outputs, 1)\n",
    "    print(predicts[:10])\n",
    "\n",
    "    # 정답 개수 구하기\n",
    "    corrects = (predicts == val_target).sum().item()  # True는 1로 연산, 정답 개수\n",
    "\n",
    "    # 정확도, 손실값 출력\n",
    "    accuracy = corrects / len(val_target)\n",
    "    loss = criterion(outputs, val_target)\n",
    "    print(f\"accuracy:{accuracy:.4f}, loss:{loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
